{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CPC251 Project Group 7 Question 1 (Machine Learning Model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading data and store the date into data frame named df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LB</th>\n",
       "      <th>AC</th>\n",
       "      <th>FM</th>\n",
       "      <th>UC</th>\n",
       "      <th>ASTV</th>\n",
       "      <th>MSTV</th>\n",
       "      <th>ALTV</th>\n",
       "      <th>MLTV</th>\n",
       "      <th>DL</th>\n",
       "      <th>DS</th>\n",
       "      <th>...</th>\n",
       "      <th>Max</th>\n",
       "      <th>Nmax</th>\n",
       "      <th>Nzeros</th>\n",
       "      <th>Mode</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Median</th>\n",
       "      <th>Variance</th>\n",
       "      <th>Tendency</th>\n",
       "      <th>CLASS</th>\n",
       "      <th>NSP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>120.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>43.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>126.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>132.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>198.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>133.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>198.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>134.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>170.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>132.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>170.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2124</th>\n",
       "      <td>140.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>27.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>169.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2125</th>\n",
       "      <td>142.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>36.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>159.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2126</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2127</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2128</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>564.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>50.7</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2129 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         LB   AC     FM    UC  ASTV  MSTV  ALTV  MLTV    DL   DS  ...    Max  \\\n",
       "0     120.0  0.0    0.0   0.0  73.0   0.5  43.0   2.4   0.0  0.0  ...  126.0   \n",
       "1     132.0  4.0    0.0   4.0  17.0   2.1   0.0  10.4   2.0  0.0  ...  198.0   \n",
       "2     133.0  2.0    0.0   5.0  16.0   2.1   0.0  13.4   2.0  0.0  ...  198.0   \n",
       "3     134.0  2.0    0.0   6.0  16.0   2.4   0.0  23.0   2.0  0.0  ...  170.0   \n",
       "4     132.0  4.0    0.0   5.0  16.0   2.4   0.0  19.9   0.0  0.0  ...  170.0   \n",
       "...     ...  ...    ...   ...   ...   ...   ...   ...   ...  ...  ...    ...   \n",
       "2124  140.0  1.0    0.0   9.0  78.0   0.4  27.0   7.0   0.0  0.0  ...  169.0   \n",
       "2125  142.0  1.0    1.0   5.0  74.0   0.4  36.0   5.0   0.0  0.0  ...  159.0   \n",
       "2126    NaN  NaN    NaN   NaN   NaN   NaN   NaN   NaN   NaN  NaN  ...    NaN   \n",
       "2127    NaN  NaN    NaN   NaN   NaN   NaN   NaN   NaN   0.0  0.0  ...    NaN   \n",
       "2128    NaN  NaN  564.0  23.0  87.0   7.0  91.0  50.7  16.0  1.0  ...    NaN   \n",
       "\n",
       "      Nmax  Nzeros   Mode   Mean  Median  Variance  Tendency  CLASS  NSP  \n",
       "0      2.0     0.0  120.0  137.0   121.0      73.0       1.0    9.0  2.0  \n",
       "1      6.0     1.0  141.0  136.0   140.0      12.0       0.0    6.0  1.0  \n",
       "2      5.0     1.0  141.0  135.0   138.0      13.0       0.0    6.0  1.0  \n",
       "3     11.0     0.0  137.0  134.0   137.0      13.0       1.0    6.0  1.0  \n",
       "4      9.0     0.0  137.0  136.0   138.0      11.0       1.0    2.0  1.0  \n",
       "...    ...     ...    ...    ...     ...       ...       ...    ...  ...  \n",
       "2124   6.0     0.0  152.0  147.0   151.0       4.0       1.0    5.0  2.0  \n",
       "2125   2.0     1.0  145.0  143.0   145.0       1.0       0.0    1.0  1.0  \n",
       "2126   NaN     NaN    NaN    NaN     NaN       NaN       NaN    NaN  NaN  \n",
       "2127   NaN     NaN    NaN    NaN     NaN       NaN       NaN    NaN  NaN  \n",
       "2128   NaN     NaN    NaN    NaN     NaN       NaN       NaN    NaN  NaN  \n",
       "\n",
       "[2129 rows x 23 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Read and check the dataset\n",
    "from sklearn import utils\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.model_selection import train_test_split\n",
    "df = pd.read_csv(\"ctg.csv\",sep=\";\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LB          3\n",
       "AC          3\n",
       "FM          2\n",
       "UC          2\n",
       "ASTV        2\n",
       "MSTV        2\n",
       "ALTV        2\n",
       "MLTV        2\n",
       "DL          1\n",
       "DS          1\n",
       "DP          1\n",
       "Width       3\n",
       "Min         3\n",
       "Max         3\n",
       "Nmax        3\n",
       "Nzeros      3\n",
       "Mode        3\n",
       "Mean        3\n",
       "Median      3\n",
       "Variance    3\n",
       "Tendency    3\n",
       "CLASS       3\n",
       "NSP         3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check for empty data\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LB</th>\n",
       "      <th>AC</th>\n",
       "      <th>FM</th>\n",
       "      <th>UC</th>\n",
       "      <th>ASTV</th>\n",
       "      <th>MSTV</th>\n",
       "      <th>ALTV</th>\n",
       "      <th>MLTV</th>\n",
       "      <th>DL</th>\n",
       "      <th>DS</th>\n",
       "      <th>...</th>\n",
       "      <th>Max</th>\n",
       "      <th>Nmax</th>\n",
       "      <th>Nzeros</th>\n",
       "      <th>Mode</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Median</th>\n",
       "      <th>Variance</th>\n",
       "      <th>Tendency</th>\n",
       "      <th>CLASS</th>\n",
       "      <th>NSP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>120.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>43.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>126.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>132.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>198.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>133.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>198.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>134.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>170.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>132.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>170.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2121</th>\n",
       "      <td>140.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>25.0</td>\n",
       "      <td>7.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>177.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2122</th>\n",
       "      <td>140.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>22.0</td>\n",
       "      <td>7.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>169.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2123</th>\n",
       "      <td>140.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>20.0</td>\n",
       "      <td>6.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>170.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2124</th>\n",
       "      <td>140.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>27.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>169.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2125</th>\n",
       "      <td>142.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>36.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>159.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2126 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         LB   AC   FM   UC  ASTV  MSTV  ALTV  MLTV   DL   DS  ...    Max  \\\n",
       "0     120.0  0.0  0.0  0.0  73.0   0.5  43.0   2.4  0.0  0.0  ...  126.0   \n",
       "1     132.0  4.0  0.0  4.0  17.0   2.1   0.0  10.4  2.0  0.0  ...  198.0   \n",
       "2     133.0  2.0  0.0  5.0  16.0   2.1   0.0  13.4  2.0  0.0  ...  198.0   \n",
       "3     134.0  2.0  0.0  6.0  16.0   2.4   0.0  23.0  2.0  0.0  ...  170.0   \n",
       "4     132.0  4.0  0.0  5.0  16.0   2.4   0.0  19.9  0.0  0.0  ...  170.0   \n",
       "...     ...  ...  ...  ...   ...   ...   ...   ...  ...  ...  ...    ...   \n",
       "2121  140.0  0.0  0.0  6.0  79.0   0.2  25.0   7.2  0.0  0.0  ...  177.0   \n",
       "2122  140.0  1.0  0.0  9.0  78.0   0.4  22.0   7.1  0.0  0.0  ...  169.0   \n",
       "2123  140.0  1.0  0.0  7.0  79.0   0.4  20.0   6.1  0.0  0.0  ...  170.0   \n",
       "2124  140.0  1.0  0.0  9.0  78.0   0.4  27.0   7.0  0.0  0.0  ...  169.0   \n",
       "2125  142.0  1.0  1.0  5.0  74.0   0.4  36.0   5.0  0.0  0.0  ...  159.0   \n",
       "\n",
       "      Nmax  Nzeros   Mode   Mean  Median  Variance  Tendency  CLASS  NSP  \n",
       "0      2.0     0.0  120.0  137.0   121.0      73.0       1.0    9.0  2.0  \n",
       "1      6.0     1.0  141.0  136.0   140.0      12.0       0.0    6.0  1.0  \n",
       "2      5.0     1.0  141.0  135.0   138.0      13.0       0.0    6.0  1.0  \n",
       "3     11.0     0.0  137.0  134.0   137.0      13.0       1.0    6.0  1.0  \n",
       "4      9.0     0.0  137.0  136.0   138.0      11.0       1.0    2.0  1.0  \n",
       "...    ...     ...    ...    ...     ...       ...       ...    ...  ...  \n",
       "2121   4.0     0.0  153.0  150.0   152.0       2.0       0.0    5.0  2.0  \n",
       "2122   6.0     0.0  152.0  148.0   151.0       3.0       1.0    5.0  2.0  \n",
       "2123   5.0     0.0  153.0  148.0   152.0       4.0       1.0    5.0  2.0  \n",
       "2124   6.0     0.0  152.0  147.0   151.0       4.0       1.0    5.0  2.0  \n",
       "2125   2.0     1.0  145.0  143.0   145.0       1.0       0.0    1.0  1.0  \n",
       "\n",
       "[2126 rows x 23 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new = df.dropna(subset = ['NSP'])# used to drop the null value in set of values of NSP\n",
    "df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2126 entries, 0 to 2125\n",
      "Data columns (total 23 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   LB        2126 non-null   float64\n",
      " 1   AC        2126 non-null   float64\n",
      " 2   FM        2126 non-null   float64\n",
      " 3   UC        2126 non-null   float64\n",
      " 4   ASTV      2126 non-null   float64\n",
      " 5   MSTV      2126 non-null   float64\n",
      " 6   ALTV      2126 non-null   float64\n",
      " 7   MLTV      2126 non-null   float64\n",
      " 8   DL        2126 non-null   float64\n",
      " 9   DS        2126 non-null   float64\n",
      " 10  DP        2126 non-null   float64\n",
      " 11  Width     2126 non-null   float64\n",
      " 12  Min       2126 non-null   float64\n",
      " 13  Max       2126 non-null   float64\n",
      " 14  Nmax      2126 non-null   float64\n",
      " 15  Nzeros    2126 non-null   float64\n",
      " 16  Mode      2126 non-null   float64\n",
      " 17  Mean      2126 non-null   float64\n",
      " 18  Median    2126 non-null   float64\n",
      " 19  Variance  2126 non-null   float64\n",
      " 20  Tendency  2126 non-null   float64\n",
      " 21  CLASS     2126 non-null   float64\n",
      " 22  NSP       2126 non-null   float64\n",
      "dtypes: float64(23)\n",
      "memory usage: 398.6 KB\n"
     ]
    }
   ],
   "source": [
    "# Check for data information\n",
    "df_new.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LB          float64\n",
       "AC          float64\n",
       "FM          float64\n",
       "UC          float64\n",
       "ASTV        float64\n",
       "MSTV        float64\n",
       "ALTV        float64\n",
       "MLTV        float64\n",
       "DL          float64\n",
       "DS          float64\n",
       "DP          float64\n",
       "Width       float64\n",
       "Min         float64\n",
       "Max         float64\n",
       "Nmax        float64\n",
       "Nzeros      float64\n",
       "Mode        float64\n",
       "Mean        float64\n",
       "Median      float64\n",
       "Variance    float64\n",
       "Tendency    float64\n",
       "CLASS       float64\n",
       "NSP         float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check for datatypes\n",
    "df_new.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LB          0\n",
       "AC          0\n",
       "FM          0\n",
       "UC          0\n",
       "ASTV        0\n",
       "MSTV        0\n",
       "ALTV        0\n",
       "MLTV        0\n",
       "DL          0\n",
       "DS          0\n",
       "DP          0\n",
       "Width       0\n",
       "Min         0\n",
       "Max         0\n",
       "Nmax        0\n",
       "Nzeros      0\n",
       "Mode        0\n",
       "Mean        0\n",
       "Median      0\n",
       "Variance    0\n",
       "Tendency    0\n",
       "CLASS       0\n",
       "NSP         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check for any missing values\n",
    "df_new.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LB</th>\n",
       "      <th>AC</th>\n",
       "      <th>FM</th>\n",
       "      <th>UC</th>\n",
       "      <th>ASTV</th>\n",
       "      <th>MSTV</th>\n",
       "      <th>ALTV</th>\n",
       "      <th>MLTV</th>\n",
       "      <th>DL</th>\n",
       "      <th>DS</th>\n",
       "      <th>...</th>\n",
       "      <th>Max</th>\n",
       "      <th>Nmax</th>\n",
       "      <th>Nzeros</th>\n",
       "      <th>Mode</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Median</th>\n",
       "      <th>Variance</th>\n",
       "      <th>Tendency</th>\n",
       "      <th>CLASS</th>\n",
       "      <th>NSP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2126.000000</td>\n",
       "      <td>2126.000000</td>\n",
       "      <td>2127.000000</td>\n",
       "      <td>2127.000000</td>\n",
       "      <td>2127.000000</td>\n",
       "      <td>2127.000000</td>\n",
       "      <td>2127.000000</td>\n",
       "      <td>2127.000000</td>\n",
       "      <td>2128.000000</td>\n",
       "      <td>2128.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2126.000000</td>\n",
       "      <td>2126.000000</td>\n",
       "      <td>2126.000000</td>\n",
       "      <td>2126.000000</td>\n",
       "      <td>2126.000000</td>\n",
       "      <td>2126.000000</td>\n",
       "      <td>2126.000000</td>\n",
       "      <td>2126.000000</td>\n",
       "      <td>2126.000000</td>\n",
       "      <td>2126.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>133.303857</td>\n",
       "      <td>2.722484</td>\n",
       "      <td>7.503056</td>\n",
       "      <td>3.669017</td>\n",
       "      <td>47.008933</td>\n",
       "      <td>1.335449</td>\n",
       "      <td>9.884814</td>\n",
       "      <td>8.207616</td>\n",
       "      <td>1.576128</td>\n",
       "      <td>0.003759</td>\n",
       "      <td>...</td>\n",
       "      <td>164.025400</td>\n",
       "      <td>4.068203</td>\n",
       "      <td>0.323612</td>\n",
       "      <td>137.452023</td>\n",
       "      <td>134.610536</td>\n",
       "      <td>138.090310</td>\n",
       "      <td>18.808090</td>\n",
       "      <td>0.320320</td>\n",
       "      <td>4.509878</td>\n",
       "      <td>1.304327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.840844</td>\n",
       "      <td>3.560850</td>\n",
       "      <td>39.030452</td>\n",
       "      <td>2.877148</td>\n",
       "      <td>17.210648</td>\n",
       "      <td>0.891543</td>\n",
       "      <td>18.476534</td>\n",
       "      <td>5.701926</td>\n",
       "      <td>2.517794</td>\n",
       "      <td>0.061213</td>\n",
       "      <td>...</td>\n",
       "      <td>17.944183</td>\n",
       "      <td>2.949386</td>\n",
       "      <td>0.706059</td>\n",
       "      <td>16.381289</td>\n",
       "      <td>15.593596</td>\n",
       "      <td>14.466589</td>\n",
       "      <td>28.977636</td>\n",
       "      <td>0.610829</td>\n",
       "      <td>3.026883</td>\n",
       "      <td>0.614377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>106.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>126.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.600000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>152.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>129.000000</td>\n",
       "      <td>125.000000</td>\n",
       "      <td>129.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>133.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.400000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>162.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>139.000000</td>\n",
       "      <td>136.000000</td>\n",
       "      <td>139.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>140.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>1.700000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>10.800000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>174.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>148.000000</td>\n",
       "      <td>145.000000</td>\n",
       "      <td>148.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>160.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>564.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>91.000000</td>\n",
       "      <td>50.700000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>238.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>187.000000</td>\n",
       "      <td>182.000000</td>\n",
       "      <td>186.000000</td>\n",
       "      <td>269.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                LB           AC           FM           UC         ASTV  \\\n",
       "count  2126.000000  2126.000000  2127.000000  2127.000000  2127.000000   \n",
       "mean    133.303857     2.722484     7.503056     3.669017    47.008933   \n",
       "std       9.840844     3.560850    39.030452     2.877148    17.210648   \n",
       "min     106.000000     0.000000     0.000000     0.000000    12.000000   \n",
       "25%     126.000000     0.000000     0.000000     1.000000    32.000000   \n",
       "50%     133.000000     1.000000     0.000000     3.000000    49.000000   \n",
       "75%     140.000000     4.000000     2.000000     5.000000    61.000000   \n",
       "max     160.000000    26.000000   564.000000    23.000000    87.000000   \n",
       "\n",
       "              MSTV         ALTV         MLTV           DL           DS  ...  \\\n",
       "count  2127.000000  2127.000000  2127.000000  2128.000000  2128.000000  ...   \n",
       "mean      1.335449     9.884814     8.207616     1.576128     0.003759  ...   \n",
       "std       0.891543    18.476534     5.701926     2.517794     0.061213  ...   \n",
       "min       0.200000     0.000000     0.000000     0.000000     0.000000  ...   \n",
       "25%       0.700000     0.000000     4.600000     0.000000     0.000000  ...   \n",
       "50%       1.200000     0.000000     7.400000     0.000000     0.000000  ...   \n",
       "75%       1.700000    11.000000    10.800000     3.000000     0.000000  ...   \n",
       "max       7.000000    91.000000    50.700000    16.000000     1.000000  ...   \n",
       "\n",
       "               Max         Nmax       Nzeros         Mode         Mean  \\\n",
       "count  2126.000000  2126.000000  2126.000000  2126.000000  2126.000000   \n",
       "mean    164.025400     4.068203     0.323612   137.452023   134.610536   \n",
       "std      17.944183     2.949386     0.706059    16.381289    15.593596   \n",
       "min     122.000000     0.000000     0.000000    60.000000    73.000000   \n",
       "25%     152.000000     2.000000     0.000000   129.000000   125.000000   \n",
       "50%     162.000000     3.000000     0.000000   139.000000   136.000000   \n",
       "75%     174.000000     6.000000     0.000000   148.000000   145.000000   \n",
       "max     238.000000    18.000000    10.000000   187.000000   182.000000   \n",
       "\n",
       "            Median     Variance     Tendency        CLASS          NSP  \n",
       "count  2126.000000  2126.000000  2126.000000  2126.000000  2126.000000  \n",
       "mean    138.090310    18.808090     0.320320     4.509878     1.304327  \n",
       "std      14.466589    28.977636     0.610829     3.026883     0.614377  \n",
       "min      77.000000     0.000000    -1.000000     1.000000     1.000000  \n",
       "25%     129.000000     2.000000     0.000000     2.000000     1.000000  \n",
       "50%     139.000000     7.000000     0.000000     4.000000     1.000000  \n",
       "75%     148.000000    24.000000     1.000000     7.000000     1.000000  \n",
       "max     186.000000   269.000000     1.000000    10.000000     3.000000  \n",
       "\n",
       "[8 rows x 23 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Describe the dataset\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LB</th>\n",
       "      <th>AC</th>\n",
       "      <th>FM</th>\n",
       "      <th>UC</th>\n",
       "      <th>ASTV</th>\n",
       "      <th>MSTV</th>\n",
       "      <th>ALTV</th>\n",
       "      <th>MLTV</th>\n",
       "      <th>DL</th>\n",
       "      <th>DS</th>\n",
       "      <th>...</th>\n",
       "      <th>Nmax</th>\n",
       "      <th>Nzeros</th>\n",
       "      <th>Mode</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Median</th>\n",
       "      <th>Variance</th>\n",
       "      <th>Tendency</th>\n",
       "      <th>CLASS</th>\n",
       "      <th>NSP</th>\n",
       "      <th>NSP_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>120.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>43.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Suspect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>132.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>133.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>134.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>132.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2121</th>\n",
       "      <td>140.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>25.0</td>\n",
       "      <td>7.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Suspect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2122</th>\n",
       "      <td>140.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>22.0</td>\n",
       "      <td>7.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Suspect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2123</th>\n",
       "      <td>140.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>20.0</td>\n",
       "      <td>6.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Suspect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2124</th>\n",
       "      <td>140.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>27.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Suspect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2125</th>\n",
       "      <td>142.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>36.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2126 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         LB   AC   FM   UC  ASTV  MSTV  ALTV  MLTV   DL   DS  ...  Nmax  \\\n",
       "0     120.0  0.0  0.0  0.0  73.0   0.5  43.0   2.4  0.0  0.0  ...   2.0   \n",
       "1     132.0  4.0  0.0  4.0  17.0   2.1   0.0  10.4  2.0  0.0  ...   6.0   \n",
       "2     133.0  2.0  0.0  5.0  16.0   2.1   0.0  13.4  2.0  0.0  ...   5.0   \n",
       "3     134.0  2.0  0.0  6.0  16.0   2.4   0.0  23.0  2.0  0.0  ...  11.0   \n",
       "4     132.0  4.0  0.0  5.0  16.0   2.4   0.0  19.9  0.0  0.0  ...   9.0   \n",
       "...     ...  ...  ...  ...   ...   ...   ...   ...  ...  ...  ...   ...   \n",
       "2121  140.0  0.0  0.0  6.0  79.0   0.2  25.0   7.2  0.0  0.0  ...   4.0   \n",
       "2122  140.0  1.0  0.0  9.0  78.0   0.4  22.0   7.1  0.0  0.0  ...   6.0   \n",
       "2123  140.0  1.0  0.0  7.0  79.0   0.4  20.0   6.1  0.0  0.0  ...   5.0   \n",
       "2124  140.0  1.0  0.0  9.0  78.0   0.4  27.0   7.0  0.0  0.0  ...   6.0   \n",
       "2125  142.0  1.0  1.0  5.0  74.0   0.4  36.0   5.0  0.0  0.0  ...   2.0   \n",
       "\n",
       "      Nzeros   Mode   Mean  Median  Variance  Tendency  CLASS  NSP  NSP_group  \n",
       "0        0.0  120.0  137.0   121.0      73.0       1.0    9.0  2.0    Suspect  \n",
       "1        1.0  141.0  136.0   140.0      12.0       0.0    6.0  1.0     Normal  \n",
       "2        1.0  141.0  135.0   138.0      13.0       0.0    6.0  1.0     Normal  \n",
       "3        0.0  137.0  134.0   137.0      13.0       1.0    6.0  1.0     Normal  \n",
       "4        0.0  137.0  136.0   138.0      11.0       1.0    2.0  1.0     Normal  \n",
       "...      ...    ...    ...     ...       ...       ...    ...  ...        ...  \n",
       "2121     0.0  153.0  150.0   152.0       2.0       0.0    5.0  2.0    Suspect  \n",
       "2122     0.0  152.0  148.0   151.0       3.0       1.0    5.0  2.0    Suspect  \n",
       "2123     0.0  153.0  148.0   152.0       4.0       1.0    5.0  2.0    Suspect  \n",
       "2124     0.0  152.0  147.0   151.0       4.0       1.0    5.0  2.0    Suspect  \n",
       "2125     1.0  145.0  143.0   145.0       1.0       0.0    1.0  1.0     Normal  \n",
       "\n",
       "[2126 rows x 24 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Copy entire dataframe into another new dataframe\n",
    "df_new_new = df_new \n",
    "categorical = pd.cut(df_new['NSP'],bins=3).value_counts(sort=False)\n",
    "#List the label\n",
    "labels = ['Normal','Suspect','Pathologic']\n",
    "#(N = normal; S = suspect; P = pathologic)\n",
    "#Respective discrete values in the data\n",
    "#Normal  : 1\n",
    "#Suspect : 2\n",
    "#Pathologic : 3\n",
    "#Increase the column named NSP_group by refering to the NSP in the original dataframe\n",
    "df_new_new['NSP_group'] = pd.cut(df['NSP'], bins=3, labels=labels)\n",
    "df_new_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1700, 22)\n",
      "(426, 22)\n",
      "(1700,)\n",
      "(426,)\n"
     ]
    }
   ],
   "source": [
    "y=df_new_new['NSP'].values\n",
    "x = df_new_new.drop(['NSP','NSP_group'],axis = 1).values\n",
    "#Split the data to train and test data\n",
    "X_train,X_test,y_train,y_test = train_test_split(x,y,test_size = 0.2,random_state=1)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Specs       Score\n",
      "21     CLASS  738.596837\n",
      "10        DP  467.882575\n",
      "4       ASTV  281.835352\n",
      "17      Mean  254.275705\n",
      "6       ALTV  245.337451\n",
      "16      Mode  230.937845\n",
      "18    Median  211.995039\n",
      "1         AC  130.720237\n",
      "19  Variance  124.450809\n",
      "5       MSTV   98.517580\n",
      "0         LB   94.721174\n"
     ]
    }
   ],
   "source": [
    "#ANOVA feature selection\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "bestfeatures = SelectKBest(score_func =f_classif, k=11)\n",
    "fit = bestfeatures.fit(X_train,y_train)\n",
    "dfscores = pd.DataFrame(fit.scores_)\n",
    "dfcolumns = pd.DataFrame(df_new.columns.drop(['NSP']))\n",
    "featureScores = pd.concat([dfcolumns,dfscores],axis=1)\n",
    "featureScores.columns = ['Specs','Score']  #naming the dataframe columns\n",
    "print(featureScores.nlargest(11,'Score'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1700, 11)\n",
      "(426, 11)\n",
      "(426,)\n",
      "(1700,)\n"
     ]
    }
   ],
   "source": [
    "#Transform test,train and validation data to 11 features after feature selection\n",
    "X_train_new = fit.transform(X_train)\n",
    "X_test_new = fit.transform(X_test)\n",
    "print(X_train_new.shape)\n",
    "print(X_test_new.shape)\n",
    "print(y_test.shape)\n",
    "print(y_train.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Before constructing a model, data distribution of the cardiotocography data set has checked\n",
    "### Undersampling method is applied if the data distribution is inequal \n",
    "###### The code below are used to check the distribution of the data and the respective graph is displayed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "g = sns.countplot(df_new['NSP'])\n",
    "g.set_xticklabels(['Normal','Suspect','Pathologic'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Undersampling method is applied as there is sufficient data and\n",
    "### Undersampling method of NearMiss version 1 is applied"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The selected machine learning algorithms are as used in the sequence of \n",
    "##### 1) Multinomial logistic regression\n",
    "##### 2) Perceptron\n",
    "##### 3) K-Nearest Classifier(KNN)\n",
    "##### 4) Decision tree\n",
    "##### 5) Support vector Machine(SVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression (Undersampling is implemented : NearMiss-1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n",
      "Training target statistics: Counter({1.0: 1329, 2.0: 227, 3.0: 144})\n",
      "Testing target statistics: Counter({1.0: 326, 2.0: 68, 3.0: 32})\n",
      "\n",
      "\n",
      "The accuracy score is  0.9131455399061033\n",
      "The f1 score is  0.8343489960941072\n",
      "The precision score is  0.8060224089635853\n",
      "The recall score is  0.8708874654156141\n",
      "\n",
      "\n",
      "            Accuracy\n",
      "Normal      0.932515\n",
      "Suspect     0.867647\n",
      "Pathologic  0.812500\n",
      "\n",
      "\n",
      "Classification report\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "     Normal       0.99      0.93      0.98      0.96      0.96      0.91       326\n",
      "    Suspect       0.70      0.87      0.93      0.78      0.90      0.80        68\n",
      " Pathologic       0.72      0.81      0.97      0.76      0.89      0.78        32\n",
      "\n",
      "avg / total       0.93      0.91      0.97      0.92      0.94      0.88       426\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Authors: Guillaume Lemaitre <g.lemaitre58@gmail.com>\n",
    "# License: MIT\n",
    "# Taken from https://imbalanced-learn.org/stable/auto_examples/applications/plot_multi_class_under_sampling.html\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix,classification_report,f1_score,recall_score,precision_score\n",
    "\n",
    "from imblearn.datasets import make_imbalance\n",
    "from imblearn.under_sampling import NearMiss\n",
    "from imblearn.pipeline import make_pipeline\n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "\n",
    "print(__doc__)\n",
    "\n",
    "RANDOM_STATE = 100 #original random stae = 42, In order to synchronous the data, change it to 100 for a while\n",
    "\n",
    "#y=df_new_new['NSP_group']\n",
    "#x = df_new.drop(['NSP'],axis = 1)\n",
    "#X_train, X_test, y_train, y_test = train_test_split(x, y, random_state=RANDOM_STATE)\n",
    "\n",
    "print(f\"Training target statistics: {Counter(y_train)}\")\n",
    "print(f\"Testing target statistics: {Counter(y_test)}\")\n",
    "print('\\n')\n",
    "\n",
    "# Create a pipeline\n",
    "pipeline = make_pipeline(\n",
    "    NearMiss(version=1), StandardScaler(), LogisticRegression(random_state=RANDOM_STATE)\n",
    ")\n",
    "pipeline.fit(X_train_new, y_train)\n",
    "y_pred_multinomial_logistic_regression_test = pipeline.predict(X_test_new)\n",
    "print(\"The accuracy score is \",accuracy_score(y_test, y_pred_multinomial_logistic_regression_test))\n",
    "print(\"The f1 score is \",f1_score(y_test, y_pred_multinomial_logistic_regression_test,average='macro'))\n",
    "print(\"The precision score is \",precision_score(y_test, y_pred_multinomial_logistic_regression_test,average='macro'))\n",
    "print(\"The recall score is \",recall_score(y_test, y_pred_multinomial_logistic_regression_test,average='macro'))\n",
    "\n",
    "cm=confusion_matrix(y_test, y_pred_multinomial_logistic_regression_test)\n",
    "cm=cm.diagonal()/cm.sum(axis=1)\n",
    "print('\\n')\n",
    "df=pd.DataFrame(cm,columns=['Accuracy'])\n",
    "df.index=[\"Normal\",\"Suspect\",\"Pathologic\"]\n",
    "print(df)\n",
    "print('\\n')\n",
    "print(\"Classification report\")\n",
    "# Classify and report the results\n",
    "print(classification_report_imbalanced(y_test, y_pred_multinomial_logistic_regression_test,target_names=['Normal','Suspect','Pathologic']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning for Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=6,\n",
       "             estimator=Pipeline(steps=[('sampling', NearMiss()),\n",
       "                                       ('scaler', StandardScaler()),\n",
       "                                       ('model', LogisticRegression())]),\n",
       "             n_jobs=3,\n",
       "             param_grid={'model__max_iter': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11,\n",
       "                                             12, 13, 14, 15, 16, 17, 18, 19, 20,\n",
       "                                             21, 22, 23, 24, 25, 26, 27, 28, 29,\n",
       "                                             30, ...],\n",
       "                         'model__multi_class': ['ovr', 'multinomial'],\n",
       "                         'model__penalty': ['l1', 'l2']},\n",
       "             refit='accuracy',\n",
       "             scoring=['accuracy', 'f1_macro', 'precision_macro',\n",
       "                      'recall_macro'])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#GridSearchCV for max iterations, multi class and penalty to improve the performance metrics \n",
    "from imblearn.under_sampling import NearMiss\n",
    "from imblearn.pipeline import Pipeline,make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "pipeline = Pipeline([('sampling',NearMiss(version=1)), ('scaler',StandardScaler()), ('model',LogisticRegression())])\n",
    "param_grid = {'model__multi_class':['ovr','multinomial'],'model__max_iter':list(range(1,200)),'model__penalty':['l1','l2']}\n",
    "gsc = GridSearchCV(pipeline, param_grid, cv=6,scoring = ['accuracy','f1_macro','precision_macro','recall_macro'], n_jobs=3, refit='accuracy')\n",
    "gsc.fit(X_train_new,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model__max_iter': 4, 'model__multi_class': 'multinomial', 'model__penalty': 'l2'}\n",
      "15\n",
      "0.9276406377013554\n"
     ]
    }
   ],
   "source": [
    "#Check the best parameters and best scores\n",
    "print(gsc.best_params_)\n",
    "print(gsc.best_index_)\n",
    "print(gsc.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression model after hyperparameter tuning is applied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score is  0.9436619718309859\n",
      "The f1 score is  0.8874926621309133\n",
      "The precision score is  0.9133769863702028\n",
      "The recall score is  0.8647825694695056\n",
      "\n",
      "\n",
      "            Accuracy\n",
      "Normal      0.987730\n",
      "Suspect     0.794118\n",
      "Pathologic  0.812500\n",
      "\n",
      "\n",
      "Classification report\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "     Normal       0.96      0.99      0.86      0.97      0.92      0.86       326\n",
      "    Suspect       0.89      0.79      0.98      0.84      0.88      0.76        68\n",
      " Pathologic       0.90      0.81      0.99      0.85      0.90      0.79        32\n",
      "\n",
      "avg / total       0.94      0.94      0.89      0.94      0.91      0.84       426\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Build Logistic Regression model using the best parameters\n",
    "pipeline = make_pipeline(\n",
    "    NearMiss(version=1), StandardScaler(), LogisticRegression(max_iter=4,multi_class='multinomial',penalty='l2',random_state=RANDOM_STATE)\n",
    ")\n",
    "pipeline.fit(X_train_new, y_train)\n",
    "y_pred_multinomial_logistic_regression_test = pipeline.predict(X_test_new)\n",
    "print(\"The accuracy score is \",accuracy_score(y_test, y_pred_multinomial_logistic_regression_test))\n",
    "print(\"The f1 score is \",f1_score(y_test, y_pred_multinomial_logistic_regression_test,average='macro'))\n",
    "print(\"The precision score is \",precision_score(y_test, y_pred_multinomial_logistic_regression_test,average='macro'))\n",
    "print(\"The recall score is \",recall_score(y_test, y_pred_multinomial_logistic_regression_test,average='macro'))\n",
    "\n",
    "cm=confusion_matrix(y_test, y_pred_multinomial_logistic_regression_test)\n",
    "cm=cm.diagonal()/cm.sum(axis=1)\n",
    "print('\\n')\n",
    "df=pd.DataFrame(cm,columns=['Accuracy'])\n",
    "df.index=[\"Normal\",\"Suspect\",\"Pathologic\"]\n",
    "print(df)\n",
    "print('\\n')\n",
    "print(\"Classification report\")\n",
    "# Classify and report the results\n",
    "print(classification_report_imbalanced(y_test, y_pred_multinomial_logistic_regression_test,target_names=['Normal','Suspect','Pathologic']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perceptron ( Undersampling is applied) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score is  0.9131455399061033\n",
      "The f1 score is  0.7930190683514721\n",
      "The precision score is  0.7792337956979983\n",
      "The recall score is  0.808398742932756\n",
      "\n",
      "\n",
      "            Accuracy\n",
      "Normal      0.960123\n",
      "Suspect     0.808824\n",
      "Pathologic  0.656250\n",
      "\n",
      "\n",
      "Classification report\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "     Normal       0.98      0.96      0.95      0.97      0.96      0.91       326\n",
      "    Suspect       0.75      0.81      0.95      0.78      0.88      0.76        68\n",
      " Pathologic       0.60      0.66      0.96      0.63      0.80      0.61        32\n",
      "\n",
      "avg / total       0.92      0.91      0.95      0.92      0.93      0.87       426\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "model_pcpt = SGDClassifier(loss='perceptron', eta0=1, learning_rate='constant',penalty=None, max_iter=200, random_state=100)\n",
    "# Create a pipeline\n",
    "pipeline = make_pipeline(NearMiss(version=1), StandardScaler(), SGDClassifier(loss='perceptron', eta0=1, learning_rate='constant',penalty=None, max_iter=200, random_state=100))\n",
    "pipeline.fit(X_train_new, y_train)\n",
    "y_pred_perceptron_test = pipeline.predict(X_test_new)\n",
    "print(\"The accuracy score is \",accuracy_score(y_test, y_pred_perceptron_test))\n",
    "print(\"The f1 score is \",f1_score(y_test, y_pred_perceptron_test,average='macro'))\n",
    "print(\"The precision score is \",precision_score(y_test, y_pred_perceptron_test,average='macro'))\n",
    "print(\"The recall score is \",recall_score(y_test, y_pred_perceptron_test,average='macro'))\n",
    "print('\\n')\n",
    "cm=confusion_matrix(y_test, y_pred_perceptron_test)\n",
    "cm=cm.diagonal()/cm.sum(axis=1)\n",
    "df=pd.DataFrame(cm,columns=['Accuracy'])\n",
    "df.index=[\"Normal\",\"Suspect\",\"Pathologic\"]\n",
    "print(df)\n",
    "print('\\n')\n",
    "print(\"Classification report\")\n",
    "# Classify and report the results\n",
    "print(classification_report_imbalanced(y_test, y_pred_perceptron_test,target_names=['Normal','Suspect','Pathologic']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning for Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=6,\n",
       "             estimator=Pipeline(steps=[('sampling', NearMiss()),\n",
       "                                       ('scaler', StandardScaler()),\n",
       "                                       ('model', SGDClassifier())]),\n",
       "             n_jobs=3,\n",
       "             param_grid={'model__max_iter': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11,\n",
       "                                             12, 13, 14, 15, 16, 17, 18, 19, 20,\n",
       "                                             21, 22, 23, 24, 25, 26, 27, 28, 29,\n",
       "                                             30, ...],\n",
       "                         'model__penalty': ['l1', 'l2']},\n",
       "             refit='accuracy',\n",
       "             scoring=['accuracy', 'f1_macro', 'precision_macro',\n",
       "                      'recall_macro'])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#GridSearchCV for max iterations and penalty to improve the performance metrics of perceptron to improve performace metrics\n",
    "pipeline = Pipeline([('sampling',NearMiss(version=1)), ('scaler',StandardScaler()), ('model',SGDClassifier())])\n",
    "param_grid = {'model__max_iter':list(range(1,200)),'model__penalty':['l1','l2']}\n",
    "gsc = GridSearchCV(pipeline, param_grid, cv=6,scoring = ['accuracy','f1_macro','precision_macro','recall_macro'], n_jobs=3, refit='accuracy')\n",
    "gsc.fit(X_train_new,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model__max_iter': 79, 'model__penalty': 'l2'}\n",
      "157\n",
      "0.925878000630402\n"
     ]
    }
   ],
   "source": [
    "#Check the best parameters and best scores\n",
    "print(gsc.best_params_)\n",
    "print(gsc.best_index_)\n",
    "print(gsc.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perceptron model after hyperparameter tuning is applied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score is  0.9342723004694836\n",
      "The f1 score is  0.8353035484019525\n",
      "The precision score is  0.8429246397354122\n",
      "The recall score is  0.8302658486707566\n",
      "\n",
      "\n",
      "            Accuracy\n",
      "Normal      0.990798\n",
      "Suspect     0.750000\n",
      "Pathologic  0.750000\n",
      "\n",
      "\n",
      "Classification report\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "     Normal       0.97      0.99      0.91      0.98      0.95      0.91       326\n",
      "    Suspect       0.85      0.75      0.97      0.80      0.86      0.71        68\n",
      " Pathologic       0.71      0.75      0.97      0.73      0.85      0.71        32\n",
      "\n",
      "avg / total       0.93      0.93      0.93      0.93      0.93      0.86       426\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Build Perceptron model using the best parameters \n",
    "# Create a pipeline\n",
    "pipeline = make_pipeline(NearMiss(version=1), StandardScaler(), SGDClassifier(loss='perceptron', eta0=1, learning_rate='constant',penalty='l2', max_iter=79, random_state=100))\n",
    "pipeline.fit(X_train_new, y_train)\n",
    "y_pred_perceptron_test = pipeline.predict(X_test_new)\n",
    "print(\"The accuracy score is \",accuracy_score(y_test, y_pred_perceptron_test))\n",
    "print(\"The f1 score is \",f1_score(y_test, y_pred_perceptron_test,average='macro'))\n",
    "print(\"The precision score is \",precision_score(y_test, y_pred_perceptron_test,average='macro'))\n",
    "print(\"The recall score is \",recall_score(y_test, y_pred_perceptron_test,average='macro'))\n",
    "print('\\n')\n",
    "cm=confusion_matrix(y_test, y_pred_perceptron_test)\n",
    "cm=cm.diagonal()/cm.sum(axis=1)\n",
    "df=pd.DataFrame(cm,columns=['Accuracy'])\n",
    "df.index=[\"Normal\",\"Suspect\",\"Pathologic\"]\n",
    "print(df)\n",
    "print('\\n')\n",
    "print(\"Classification report\")\n",
    "# Classify and report the results\n",
    "print(classification_report_imbalanced(y_test, y_pred_perceptron_test,target_names=['Normal','Suspect','Pathologic']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN classifier (Undersampling applied)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score is  0.9389671361502347\n",
      "The f1 score is  0.867856168654041\n",
      "The precision score is  0.8780687265189792\n",
      "The recall score for is  0.8588581137976664\n",
      "\n",
      "\n",
      "            Accuracy\n",
      "Normal      0.984663\n",
      "Suspect     0.779412\n",
      "Pathologic  0.812500\n",
      "\n",
      "\n",
      "Classification report\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "     Normal       0.97      0.98      0.89      0.98      0.94      0.88       326\n",
      "    Suspect       0.85      0.78      0.97      0.82      0.87      0.74        68\n",
      " Pathologic       0.81      0.81      0.98      0.81      0.89      0.79        32\n",
      "\n",
      "avg / total       0.94      0.94      0.91      0.94      0.92      0.85       426\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### KNN classifier(undersampling is applied)\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "model_knn = KNeighborsClassifier()\n",
    "# Create a pipeline\n",
    "pipeline = make_pipeline(NearMiss(version=1), StandardScaler(), KNeighborsClassifier())\n",
    "pipeline.fit(X_train_new, y_train)\n",
    "y_pred_knn_classifier_test = pipeline.predict(X_test_new)\n",
    "print(\"The accuracy score is \",accuracy_score(y_test, y_pred_knn_classifier_test))\n",
    "print(\"The f1 score is \",f1_score(y_test, y_pred_knn_classifier_test,average='macro'))\n",
    "print(\"The precision score is \",precision_score(y_test, y_pred_knn_classifier_test,average='macro'))\n",
    "print(\"The recall score for is \",recall_score(y_test, y_pred_knn_classifier_test,average='macro'))\n",
    "cm=confusion_matrix(y_test, y_pred_knn_classifier_test)\n",
    "cm=cm.diagonal()/cm.sum(axis=1)\n",
    "print('\\n')\n",
    "df=pd.DataFrame(cm,columns=['Accuracy'])\n",
    "df.index=[\"Normal\",\"Suspect\",\"Pathologic\"]\n",
    "print(df)\n",
    "print('\\n')\n",
    "print(\"Classification report\")\n",
    "print(classification_report_imbalanced(y_test, y_pred_knn_classifier_test,target_names=['Normal','Suspect','Pathologic']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning for KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=6,\n",
       "             estimator=Pipeline(steps=[('sampling', NearMiss()),\n",
       "                                       ('scaler', StandardScaler()),\n",
       "                                       ('model', KNeighborsClassifier())]),\n",
       "             n_jobs=3,\n",
       "             param_grid={'model__leaf_size': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11,\n",
       "                                              12, 13, 14, 15, 16, 17, 18, 19,\n",
       "                                              20, 21, 22, 23, 24, 25, 26, 27,\n",
       "                                              28, 29],\n",
       "                         'model__n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10,\n",
       "                                                11, 12, 13, 14, 15, 16, 17, 18,\n",
       "                                                19]},\n",
       "             refit='accuracy',\n",
       "             scoring=['accuracy', 'f1_macro', 'precision_macro',\n",
       "                      'recall_macro'])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#GridSearchCV for n_neighbors and leaf_size for KNN to improve performace metrics\n",
    "from imblearn.under_sampling import NearMiss\n",
    "from imblearn.pipeline import Pipeline,make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "pipeline = Pipeline([('sampling',NearMiss(version=1)), ('scaler',StandardScaler()), ('model',KNeighborsClassifier())])\n",
    "param_grid = {'model__n_neighbors':list(range(1,20)),'model__leaf_size':list(range(1,30))}\n",
    "gsc = GridSearchCV(pipeline, param_grid, cv=6,scoring = ['accuracy','f1_macro','precision_macro','recall_macro'], n_jobs=3, refit='accuracy')\n",
    "gsc.fit(X_train_new,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model__leaf_size': 1, 'model__n_neighbors': 2}\n",
      "1\n",
      "0.9494060949916222\n"
     ]
    }
   ],
   "source": [
    "#Check for the best parameters\n",
    "print(gsc.best_params_)\n",
    "print(gsc.best_index_)\n",
    "print(gsc.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN model after hyperparameter tuning is applied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score is  0.960093896713615\n",
      "The f1 score is  0.898766358677666\n",
      "The precision score is  0.920053191889311\n",
      "The recall score for is  0.8841874172982077\n",
      "\n",
      "\n",
      "            Accuracy\n",
      "Normal      0.990798\n",
      "Suspect     0.911765\n",
      "Pathologic  0.750000\n",
      "\n",
      "\n",
      "Classification report\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "     Normal       0.99      0.99      0.96      0.99      0.98      0.95       326\n",
      "    Suspect       0.85      0.91      0.97      0.88      0.94      0.88        68\n",
      " Pathologic       0.92      0.75      0.99      0.83      0.86      0.73        32\n",
      "\n",
      "avg / total       0.96      0.96      0.96      0.96      0.96      0.93       426\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Build KNN model using the best parameters\n",
    "pipeline = make_pipeline(NearMiss(version=1), StandardScaler(), KNeighborsClassifier(n_neighbors=2,leaf_size=1))\n",
    "pipeline.fit(X_train_new, y_train)\n",
    "y_pred_knn_classifier_test = pipeline.predict(X_test_new)\n",
    "print(\"The accuracy score is \",accuracy_score(y_test, y_pred_knn_classifier_test))\n",
    "print(\"The f1 score is \",f1_score(y_test, y_pred_knn_classifier_test,average='macro'))\n",
    "print(\"The precision score is \",precision_score(y_test, y_pred_knn_classifier_test,average='macro'))\n",
    "print(\"The recall score for is \",recall_score(y_test, y_pred_knn_classifier_test,average='macro'))\n",
    "cm=confusion_matrix(y_test, y_pred_knn_classifier_test)\n",
    "cm=cm.diagonal()/cm.sum(axis=1)\n",
    "print('\\n')\n",
    "df=pd.DataFrame(cm,columns=['Accuracy'])\n",
    "df.index=[\"Normal\",\"Suspect\",\"Pathologic\"]\n",
    "print(df)\n",
    "print('\\n')\n",
    "print(\"Classification report\")\n",
    "print(classification_report_imbalanced(y_test, y_pred_knn_classifier_test,target_names=['Normal','Suspect','Pathologic']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree (Undersampling is applied) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score is  0.9483568075117371\n",
      "The f1 score is  0.9342390083419724\n",
      "The precision score is  0.9238756613756612\n",
      "The recall score is  0.9487136112113558\n",
      "\n",
      "\n",
      "            Accuracy\n",
      "Normal      0.950920\n",
      "Suspect     0.926471\n",
      "Pathologic  0.968750\n",
      "\n",
      "\n",
      "Classification report\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "     Normal       0.98      0.95      0.95      0.97      0.95      0.90       326\n",
      "    Suspect       0.79      0.93      0.95      0.85      0.94      0.88        68\n",
      " Pathologic       1.00      0.97      1.00      0.98      0.98      0.97        32\n",
      "\n",
      "avg / total       0.95      0.95      0.95      0.95      0.95      0.90       426\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "model_dt = DecisionTreeClassifier(criterion='gini', random_state=1)\n",
    "# Create a pipeline\n",
    "pipeline = make_pipeline(NearMiss(version=1), StandardScaler(), DecisionTreeClassifier(criterion='gini', random_state=0))\n",
    "pipeline.fit(X_train_new, y_train)\n",
    "y_pred_decision_tree_test = pipeline.predict(X_test_new)\n",
    "print(\"The accuracy score is \",accuracy_score(y_test, y_pred_decision_tree_test ))\n",
    "print(\"The f1 score is \",f1_score(y_test, y_pred_decision_tree_test,average='macro'))\n",
    "print(\"The precision score is \",precision_score(y_test, y_pred_decision_tree_test,average='macro'))\n",
    "print(\"The recall score is \", recall_score(y_test, y_pred_decision_tree_test,average='macro'))\n",
    "cm=confusion_matrix(y_test, y_pred_decision_tree_test)\n",
    "cm=cm.diagonal()/cm.sum(axis=1)\n",
    "print('\\n')\n",
    "df=pd.DataFrame(cm,columns=['Accuracy'])\n",
    "df.index=[\"Normal\",\"Suspect\",\"Pathologic\"]\n",
    "print(df)\n",
    "print('\\n')\n",
    "# Classify and report the results\n",
    "print(\"Classification report\")\n",
    "print(classification_report_imbalanced(y_test, y_pred_decision_tree_test,target_names=['Normal','Suspect','Pathologic']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning for Decision Tree algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=6,\n",
       "             estimator=Pipeline(steps=[('sampling', NearMiss()),\n",
       "                                       ('scaler', StandardScaler()),\n",
       "                                       ('model', DecisionTreeClassifier())]),\n",
       "             n_jobs=3,\n",
       "             param_grid={'model__criterion': ['gini', 'entropy'],\n",
       "                         'model__max_depth': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11,\n",
       "                                              12, 13, 14, 15, 16, 17, 18, 19,\n",
       "                                              20, 21, 22, 23, 24, 25, 26, 27,\n",
       "                                              28, 29],\n",
       "                         'model__min_samples_split': [15, 20, 25, 30],\n",
       "                         'model__random_state': [0, 1, 2]},\n",
       "             refit='accuracy',\n",
       "             scoring=['accuracy', 'f1_macro', 'precision_macro',\n",
       "                      'recall_macro'])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#GridSearchCV for criterion and max depths, random states and min samples split for decision tree to improve performace metrics\n",
    "pipeline = Pipeline([('sampling',NearMiss(version=1)), ('scaler',StandardScaler()), ('model',DecisionTreeClassifier())])\n",
    "param_grid = {'model__criterion':['gini','entropy'],'model__max_depth':list(range(1,30)),'model__random_state':[0,1,2],'model__min_samples_split':[15,20,25,30]}\n",
    "gsc = GridSearchCV(pipeline, param_grid, cv=6,scoring = ['accuracy','f1_macro','precision_macro','recall_macro'], n_jobs=3, refit='accuracy')\n",
    "gsc.fit(X_train_new,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model__criterion': 'entropy', 'model__max_depth': 2, 'model__min_samples_split': 15, 'model__random_state': 0}\n",
      "360\n",
      "0.9087741999701388\n"
     ]
    }
   ],
   "source": [
    "#Check for best parameters and scores\n",
    "print(gsc.best_params_)\n",
    "print(gsc.best_index_)\n",
    "print(gsc.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree model after hyperparameter tuning is applied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score is  0.960093896713615\n",
      "The f1 score is  0.939893006850002\n",
      "The precision score is  0.9781161499135681\n",
      "The recall score is  0.9111519607843137\n",
      "\n",
      "\n",
      "            Accuracy\n",
      "Normal      1.000000\n",
      "Suspect     0.764706\n",
      "Pathologic  0.968750\n",
      "\n",
      "\n",
      "Classification report\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "     Normal       0.95      1.00      0.84      0.98      0.92      0.85       326\n",
      "    Suspect       0.98      0.76      1.00      0.86      0.87      0.74        68\n",
      " Pathologic       1.00      0.97      1.00      0.98      0.98      0.97        32\n",
      "\n",
      "avg / total       0.96      0.96      0.88      0.96      0.91      0.84       426\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Build a decision tree model with the best parameters\n",
    "pipelineBestDT = make_pipeline(NearMiss(version=1), StandardScaler(), DecisionTreeClassifier(criterion='entropy',max_depth=2,random_state=0,min_samples_split=15))\n",
    "pipelineBestDT.fit(X_train_new, y_train)\n",
    "y_pred_decision_tree_test = pipelineBestDT.predict(X_test_new)\n",
    "print(\"The accuracy score is \",accuracy_score(y_test, y_pred_decision_tree_test ))\n",
    "print(\"The f1 score is \",f1_score(y_test, y_pred_decision_tree_test,average='macro'))\n",
    "print(\"The precision score is \",precision_score(y_test, y_pred_decision_tree_test,average='macro'))\n",
    "print(\"The recall score is \", recall_score(y_test, y_pred_decision_tree_test,average='macro'))\n",
    "cm=confusion_matrix(y_test, y_pred_decision_tree_test)\n",
    "cm=cm.diagonal()/cm.sum(axis=1)\n",
    "print('\\n')\n",
    "df=pd.DataFrame(cm,columns=['Accuracy'])\n",
    "df.index=[\"Normal\",\"Suspect\",\"Pathologic\"]\n",
    "print(df)\n",
    "print('\\n')\n",
    "print(\"Classification report\")\n",
    "print(classification_report_imbalanced(y_test, y_pred_decision_tree_test,target_names=['Normal','Suspect','Pathologic']))\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support vector machine (Undersampling is applied) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score is  0.9460093896713615\n",
      "The f1 score is  0.8642797300642631\n",
      "The precision score is  0.8832410101732711\n",
      "The recall score is 0.8515051726211956\n",
      "\n",
      "\n",
      "            Accuracy\n",
      "Normal      0.984663\n",
      "Suspect     0.882353\n",
      "Pathologic  0.687500\n",
      "\n",
      "\n",
      "Classification report\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "     Normal       0.98      0.98      0.94      0.98      0.96      0.93       326\n",
      "    Suspect       0.82      0.88      0.96      0.85      0.92      0.84        68\n",
      " Pathologic       0.85      0.69      0.99      0.76      0.82      0.66        32\n",
      "\n",
      "avg / total       0.95      0.95      0.95      0.95      0.95      0.90       426\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#### Undersampling is applied\n",
    "from sklearn.svm import SVC\n",
    "C = 0.1\n",
    "# Create a pipeline\n",
    "pipeline = make_pipeline(NearMiss(version=1), StandardScaler(), SVC(kernel='linear', C=C))\n",
    "pipeline.fit(X_train_new, y_train)\n",
    "y_pred_SVM_test = pipeline.predict(X_test_new)\n",
    "print(\"The accuracy score is \",accuracy_score(y_test, y_pred_SVM_test ))\n",
    "print(\"The f1 score is \",f1_score(y_test, y_pred_SVM_test,average='macro'))\n",
    "print(\"The precision score is \",precision_score(y_test, y_pred_SVM_test,average='macro'))\n",
    "print(\"The recall score is\", recall_score(y_test, y_pred_SVM_test,average='macro'))\n",
    "cm=confusion_matrix(y_test, y_pred_SVM_test)\n",
    "cm=cm.diagonal()/cm.sum(axis=1)\n",
    "print('\\n')\n",
    "df=pd.DataFrame(cm,columns=['Accuracy'])\n",
    "df.index=[\"Normal\",\"Suspect\",\"Pathologic\"]\n",
    "print(df)\n",
    "print('\\n')\n",
    "# Classify and report the results\n",
    "print(\"Classification report\")\n",
    "print(classification_report_imbalanced(y_test, y_pred_SVM_test,target_names=['Normal','Suspect','Pathologic']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning for SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=6,\n",
       "             estimator=Pipeline(steps=[('sampling', NearMiss()),\n",
       "                                       ('scaler', StandardScaler()),\n",
       "                                       ('model', SVC())]),\n",
       "             n_jobs=3,\n",
       "             param_grid={'model__C': [0.1, 1, 5], 'model__degree': [2, 3, 4],\n",
       "                         'model__kernel': ['poly', 'rbf', 'linear']},\n",
       "             refit='accuracy',\n",
       "             scoring=['accuracy', 'f1_macro', 'precision_macro',\n",
       "                      'recall_macro'])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#GridSearchCV for kernel and C and degree to improve performace metrics\n",
    "pipeline = Pipeline([('sampling',NearMiss(version=1)), ('scaler',StandardScaler()), ('model',SVC())])\n",
    "param_grid = {'model__kernel':['poly', 'rbf','linear'],'model__C':[0.1, 1, 5],'model__degree':[2,3,4]}\n",
    "gsc = GridSearchCV(pipeline, param_grid, cv=6,scoring = ['accuracy','f1_macro','precision_macro','recall_macro'], n_jobs=3, refit='accuracy')\n",
    "gsc.fit(X_train_new,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model__C': 1, 'model__degree': 2, 'model__kernel': 'linear'}\n",
      "11\n",
      "0.9494102423729657\n"
     ]
    }
   ],
   "source": [
    "#Check for best parameters and scores\n",
    "print(gsc.best_params_)\n",
    "print(gsc.best_index_)\n",
    "print(gsc.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM model after hyperparameter tuning is applied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score is  0.9577464788732394\n",
      "The f1 score is  0.899276852180078\n",
      "The precision score is  0.9015432098765431\n",
      "The recall score is 0.8980738000721761\n",
      "\n",
      "\n",
      "            Accuracy\n",
      "Normal      0.984663\n",
      "Suspect     0.897059\n",
      "Pathologic  0.812500\n",
      "\n",
      "\n",
      "Classification report\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "     Normal       0.99      0.98      0.97      0.99      0.98      0.96       326\n",
      "    Suspect       0.85      0.90      0.97      0.87      0.93      0.86        68\n",
      " Pathologic       0.87      0.81      0.99      0.84      0.90      0.79        32\n",
      "\n",
      "avg / total       0.96      0.96      0.97      0.96      0.96      0.93       426\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Build SVM model using the best parameters\n",
    "pipeline = make_pipeline(NearMiss(version=1), StandardScaler(), SVC(kernel='linear', C=1,degree=2))\n",
    "pipeline.fit(X_train_new, y_train)\n",
    "y_pred_SVM_test = pipeline.predict(X_test_new)\n",
    "print(\"The accuracy score is \",accuracy_score(y_test, y_pred_SVM_test ))\n",
    "print(\"The f1 score is \",f1_score(y_test, y_pred_SVM_test,average='macro'))\n",
    "print(\"The precision score is \",precision_score(y_test, y_pred_SVM_test,average='macro'))\n",
    "print(\"The recall score is\", recall_score(y_test, y_pred_SVM_test,average='macro'))\n",
    "cm=confusion_matrix(y_test, y_pred_SVM_test)\n",
    "cm=cm.diagonal()/cm.sum(axis=1)\n",
    "print('\\n')\n",
    "df=pd.DataFrame(cm,columns=['Accuracy'])\n",
    "df.index=[\"Normal\",\"Suspect\",\"Pathologic\"]\n",
    "print(df)\n",
    "print('\\n')\n",
    "# Classify and report the results\n",
    "print(\"Classification report\")\n",
    "print(classification_report_imbalanced(y_test, y_pred_SVM_test,target_names=['Normal','Suspect','Pathologic']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### After running 5 machine learning algorithms, the algorithm with the highest accuracy, recall, f1-score, precision are chosen\n",
    "#### The accuracy, f1, precision and recall scores are stored into a dataframe named df_accuracy_table to compare the efficiency of 5 machine learning algorithms. Those performance metrics are calculated after hyperparameter tuning is done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Machine learning algorithm</th>\n",
       "      <th>Accuracy score</th>\n",
       "      <th>F1 score</th>\n",
       "      <th>Precision score</th>\n",
       "      <th>Recall score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>K-Nearest Neighbour</td>\n",
       "      <td>0.960094</td>\n",
       "      <td>0.898766</td>\n",
       "      <td>0.920053</td>\n",
       "      <td>0.884187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Perceptron</td>\n",
       "      <td>0.934272</td>\n",
       "      <td>0.835304</td>\n",
       "      <td>0.842925</td>\n",
       "      <td>0.830266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Multinomial logistic regression</td>\n",
       "      <td>0.943662</td>\n",
       "      <td>0.887493</td>\n",
       "      <td>0.913377</td>\n",
       "      <td>0.864783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Decision tree</td>\n",
       "      <td>0.960094</td>\n",
       "      <td>0.939893</td>\n",
       "      <td>0.978116</td>\n",
       "      <td>0.911152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>0.957746</td>\n",
       "      <td>0.899277</td>\n",
       "      <td>0.901543</td>\n",
       "      <td>0.898074</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Machine learning algorithm  Accuracy score  F1 score  Precision score  \\\n",
       "0              K-Nearest Neighbour        0.960094  0.898766         0.920053   \n",
       "1                       Perceptron        0.934272  0.835304         0.842925   \n",
       "2  Multinomial logistic regression        0.943662  0.887493         0.913377   \n",
       "3                    Decision tree        0.960094  0.939893         0.978116   \n",
       "4           Support Vector Machine        0.957746  0.899277         0.901543   \n",
       "\n",
       "   Recall score  \n",
       "0      0.884187  \n",
       "1      0.830266  \n",
       "2      0.864783  \n",
       "3      0.911152  \n",
       "4      0.898074  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#accuracy.columns = ['Machine learning algorithm','Accuracy score','F1 score','Precision score','Recall score']\n",
    "#A dictionary is created \n",
    "data = {'Machine learning algorithm': \n",
    "        ['K-Nearest Neighbour', 'Perceptron', 'Multinomial logistic regression', 'Decision tree','Support Vector Machine']}\n",
    "#Convert the dictionary into dataframe\n",
    "df_accuracy_table = pd.DataFrame(data)\n",
    "#Define an array named result to store the accuracy score for respective machine learning algorithm\n",
    "result = []\n",
    "for value in df_accuracy_table[\"Machine learning algorithm\"]:\n",
    "    if value == \"K-Nearest Neighbour\":\n",
    "        result.append(accuracy_score(y_test, y_pred_knn_classifier_test))\n",
    "    elif value == \"Perceptron\":\n",
    "        result.append(accuracy_score(y_test, y_pred_perceptron_test ))\n",
    "    elif value == \"Multinomial logistic regression\":\n",
    "        result.append(accuracy_score(y_test, y_pred_multinomial_logistic_regression_test))\n",
    "    elif value == \"Decision tree\":\n",
    "        result.append(accuracy_score(y_test, y_pred_decision_tree_test ))\n",
    "    elif value == \"Support Vector Machine\":\n",
    "        result.append(accuracy_score(y_test, y_pred_SVM_test))\n",
    "    else:\n",
    "        break\n",
    "\n",
    "#Define an array named result2 to store the f1 score for respective machine learning algorithm\n",
    "result2 = []\n",
    "for value in df_accuracy_table[\"Machine learning algorithm\"]:\n",
    "    if value == \"K-Nearest Neighbour\":\n",
    "        result2.append(f1_score(y_test, y_pred_knn_classifier_test,average='macro'))\n",
    "    elif value == \"Perceptron\":\n",
    "        result2.append(f1_score(y_test, y_pred_perceptron_test,average='macro' ))\n",
    "    elif value == \"Multinomial logistic regression\":\n",
    "        result2.append(f1_score(y_test, y_pred_multinomial_logistic_regression_test,average='macro'))\n",
    "    elif value == \"Decision tree\":\n",
    "        result2.append(f1_score(y_test, y_pred_decision_tree_test,average='macro' ))\n",
    "    elif value == \"Support Vector Machine\":\n",
    "        result2.append(f1_score(y_test, y_pred_SVM_test,average='macro'))\n",
    "    else:\n",
    "        break\n",
    "\n",
    "#Define an array named result3 to store the precision score for resptive machine learning algorithm\n",
    "result3 = []\n",
    "for value in df_accuracy_table[\"Machine learning algorithm\"]:\n",
    "    if value == \"K-Nearest Neighbour\":\n",
    "        result3.append(precision_score(y_test, y_pred_knn_classifier_test,average='macro'))\n",
    "    elif value == \"Perceptron\":\n",
    "        result3.append(precision_score(y_test, y_pred_perceptron_test,average='macro' ))\n",
    "    elif value == \"Multinomial logistic regression\":\n",
    "        result3.append(precision_score(y_test, y_pred_multinomial_logistic_regression_test,average='macro'))\n",
    "    elif value == \"Decision tree\":\n",
    "        result3.append(precision_score(y_test, y_pred_decision_tree_test,average='macro' ))\n",
    "    elif value == \"Support Vector Machine\":\n",
    "        result3.append(precision_score(y_test, y_pred_SVM_test,average='macro'))\n",
    "    else:\n",
    "        break\n",
    "#Define an array named result4 to store the recall score for resptive machine learning algorithm        \n",
    "result4 = []\n",
    "for value in df_accuracy_table[\"Machine learning algorithm\"]:\n",
    "    if value == \"K-Nearest Neighbour\":\n",
    "        result4.append(recall_score(y_test, y_pred_knn_classifier_test,average='macro'))\n",
    "    elif value == \"Perceptron\":\n",
    "        result4.append(recall_score(y_test, y_pred_perceptron_test,average='macro' ))\n",
    "    elif value == \"Multinomial logistic regression\":\n",
    "        result4.append(recall_score(y_test, y_pred_multinomial_logistic_regression_test,average='macro'))\n",
    "    elif value == \"Decision tree\":\n",
    "        result4.append(recall_score(y_test, y_pred_decision_tree_test,average='macro' ))\n",
    "    elif value == \"Support Vector Machine\":\n",
    "        result4.append(recall_score(y_test, y_pred_SVM_test,average='macro'))\n",
    "    else:\n",
    "        break\n",
    "\n",
    "df_accuracy_table[\"Accuracy score\"] = result   \n",
    "df_accuracy_table[\"F1 score\"] = result2 \n",
    "df_accuracy_table[\"Precision score\"] = result3 \n",
    "df_accuracy_table[\"Recall score\"] = result4 \n",
    "df_accuracy_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### -----------------------------------------------\"End of Question 1\"-----------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
